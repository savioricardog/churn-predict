# üöú Classifica√ß√£o de Clientes que dar√£o Churn (Catboost)

![Python](https://img.shields.io/badge/Python-3.9-blue)
![CatBoost](https://img.shields.io/badge/Model-CatBoost-orange)
![MLflow](https://img.shields.io/badge/Tracking-MLflow-blue)
![Status](https://img.shields.io/badge/Status-Conclu√≠do-green)

## üìã Sobre o Projeto
Este projeto resolve um problema muito comum em toda e qualquer empresa: Churn de clientes.

O principal desafio neste caso/projeto √© conseguir entender as oscila√ß√µes do comportamento humano, para assim conseguir tra√ßar um padr√£o de perfil de usu√°rios que da churn.

## üìã Entendimento de neg√≥cios.
Realizando EDA pode-se concluir alguns padr√µes que ajudam a basear a classifi√ß√£o de Churn para tal Cliente.
Clientes mais propensos a churn utilizam menos produtos que clientes menos propensos.

## üß† Estrat√©gia de Modelagem

### 1. Algoritmo escolhido e Param√™tros
Utilizei o **Catboost Classifier** com a fun√ß√£o hiperparametros como **Learning Rate** (`0.01`) e **Class_Weight** (`balanced`).
* **Por que o Catboost venceu XGB, LGBM e RF?** Geralmente modelos boosting (XGB E LGBM) se sobressaem em analises preditivas, por√©m neste case, o Catboost se sobressaiu por conta de uma caracter√≠stica que ele possui. Trato com vari√°veis categoricas. Por conta deste dataset ser majoritariamente formado por vari√°veis categ√≥ricas, ele acaba sendo o tipo de base perfeita para o Catboost performar, que foi o que ocorreu nessa rodada de treinos.
* **Por que Learning Rate e Class_Weight?** Por que no caso de an√°lise de churns o mais d√≠ficil √© aprender o padr√£o de comportamento numa base t√£o desbalanceada, e neste caso, a melhor solu√ß√£o √© fazer que o modelo se atende a todo e qualquer detalhe no treinamento, fazendo com que o modelo n√£o passe por um comportamento ou indicio de poss√≠vel churn sem detect√°-la. Em conjunto com ele, o param√™tro class_weight ajuda muito dizendo para o modelo dar mais enfoque na classe minorit√°ria (aumenta o peso da classe churn e ajuda o modelo a "ter medo" de perder poss√≠veis clientes churners).

### 2. Engenharia de Features
A estrutura de dados foi constru√≠da com `Scikit-Learn` incluindo:
* **Scaling:** do **"Total Charges"** e das features num√©ricas para menores escalas.
* **Imputer:** da mediana em features num√©ricas com missings e valores constantes em features categ√≥ricas.
* **Enconding:** em features cat√©goricas.
* **Limpeza e Transforma√ß√£o:** na feature **"Total Charges"** por conta de registro de espa√ßo na coluna.


## üìä Resultados (Teste baseline Pr√© calibra√ß√£o com Threshold)

| M√©tricas | Valor Final |
|----------|-------------|
| **Threshold** | **0.50** (Calibrador de probabilidades padr√£o do modelo) |
| **Precision** | **55%** (Assertividade percentual dos apontamentos de fraude) |
| **Recall**    | **79%** (Capacidade de detec√ß√£o) |
| **F1-Score**  | **65%** (Equil√≠brio entre Precision x Recall) |
| **ROC AUC**   | **78%** (Capacidade de separa√ß√£o entre Churn e N√£o churn) |

### Performance Teste: Curva de Calibra√ß√£o Padr√£o
> *O gr√°fico linha abaixo mostra como se comportou o modelo durante o teste, e sua performance de calibra√ß√£o comparada ao modelo perfeito*

![Curva de Calibra√ß√£o](img/calibration_curve_test.png)

### Performance Financeira Teste
> *O gr√°fico de barras abaixo mostra o resultado financeiro do modelo no Teste.
Entregando um valor de **$753 Mil** dolares de churns evitados, que equivalem a **36%** do valor total movimentado pelos clientes na base teste (com Threshold √≥timo de lucro para a base teste em 0.17 e Threshold √≥timo para o modelo em 0.5)*

![Resultado Financeiro Test](img/business_profit_curve_test.png)

## üìä Resultados (Valida√ß√£o com Threshold)

| M√©tricas | Valor Final |
|----------|-------------|
| **Threshold** | **0.30** (Calibrador √≥timo de probabilidades da base de valida√ß√£o) |
| **Precision** | **69%** (Assertividade percentual dos apontamentos de fraude) |
| **Recall**    | **61%** (Capacidade de detec√ß√£o) |
| **F1-Score**  | **65%** (Equil√≠brio entre Precision x Recall) |
| **ROC AUC**   | **81%** (Capacidade de separa√ß√£o entre Churn e N√£o churn) |


### Performance Calibrada: Curva de Calibra√ß√£o
> *O gr√°fico linha abaixo mostra como se comportou o modelo durante a valida√ß√£o com o threshold perfeito definido, e sua performance de calibra√ß√£o comparada ao modelo de teste e o modelo perfeito*

![Curva de Calibra√ß√£o Final](img/calibration_curve_val.png)


### Performance Financeira Calibrada
> *O gr√°fico de barras abaixo mostra o resultado financeiro do modelo na valida√ß√£o.
Entregando um valor de **$388 Mil** dolares de churns evitados, que equivalem a **37%** do valor total movimentado pelos clientes na base de valida√ß√£o (com Threshold √≥timo de lucro para a base de valida√ß√£o em 0.11 e Threshold √≥timo para o modelo em 0.3)*


![Resultado Financeiro Calibrada](img/business_profit_curve_final.png)

## Conclus√£o e Recomenda√ß√£o de Neg√≥cio
**A escolha do ponto de opera√ß√£o do modelo depende da estrat√©gia moment√¢nea da empresa, apresentando dois cen√°rios distintos:**
* **1. Estrat√©gia de "Prote√ß√£o Agressiva" (Threshold 0.11):** 
   * **Foco:** Maximizar a reten√ß√£o financeira a qualquer custo (Lucro L√≠quido Estimado: M√°ximo).
   
   * **Cen√°rio ideal:** Campanhas de baixo custo operacional (ex: E-mail automatizado, SMS, Push Notification) onde o custo de um "Falso Positivo" √© irris√≥rio.
   
   * **Risco:** Abordar uma grande parcela da base, gerando poss√≠veis descontos desnecess√°rios (canibaliza√ß√£o) para clientes que n√£o sairiam.
* **2. Estrat√©gia "Cir√∫rgica / Efici√™ncia Operacional" (Threshold 0.30):** 
   * **Foco:** Equil√≠brio entre recupera√ß√£o de receita e precis√£o da equipe (Melhor F1-Score).
s
   * **Cen√°rio ideal:** A√ß√µes de alto custo (ex: Liga√ß√£o de Gerente de Conta, Reten√ß√£o ativa via Call Center) onde o tempo da equipe √© limitado.
   
   * **Vantagem:** Evita o desgaste da base de clientes fi√©is e garante que cada contato tenha uma alta probabilidade de convers√£o.

* **Recomenda√ß√£o Final:** Considerando que o custo de reten√ß√£o simulado foi baixo (5% da m√©dia do LTV), recomenda-se iniciar com uma abordagem h√≠brida (ex: Threshold 0.20), monitorando a taxa de convers√£o da equipe de reten√ß√£o e ajustando a r√©gua conforme a capacidade operacional.

## üöÄ Como Rodar o Projeto

1. **Clone o reposit√≥rio:**
   ```bash
   git clone [git@github.com:savioricardog/churn-predict.git](https://github.com/savioricardog/churn-predict.git)

2. **Instale as depend√™ncias:**
   ```bash 
   pip install -r requirements.txt

3. **Execute o arquivos :**
   ```bash 
   python src/train_pipeline.py

## üìÇ Estrutura de Arquivos 

* **churn-predict.py:** Estrutura principal de treinamento.

* **churn-predict.ipynb:** Arquivo em modelo Jupyter.

* **requirements.txt:** Depend√™ncias do ambiente.

* **model:**
   * **import MlFlow**
   * **Carregar o modelo diretamente do MLFlow:**
      * mlflow.set_tracking_uri("http://seu-servidor-mlflow:5000")
      * versions = mlflow.search_model_versions(filter_string= "name = 'model_churn'") 
      * last_version = max([int(i.version) for i in versions])
      * model = mlflow.sklearn.load_model(f"models:///model_churn/{last_version}")
      * predictions = model.predict(data)

**Desenvolvido por Savio Ricardo Garcia üë®‚Äçüíª**
