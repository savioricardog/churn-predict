# ğŸšœ ClassificaÃ§Ã£o de Clientes que darÃ£o Churn (Catboost)

## ğŸ“‹ Sobre o Projeto
Este projeto resolve um problema muito comum em toda e qualquer empresa: Churn de clientes.

O principal desafio neste caso/projeto Ã© conseguir entender as ocilaÃ§Ãµes do comportamento humano, para assim conseguir traÃ§ar um padrÃ£o de perfil de usuÃ¡rios que da churn.

## ğŸ“‹ Entendimento de nÃ©gocios.
Realizando EDA pode-se concluir alguns padrÃµes que ajudam a basear a classifiÃ§Ã£o de Churn para tal Cliente.
Clientes mais propensos a churn utilizam menos produtos que clientes menos propensos.

## ğŸ§  EstratÃ©gia de Modelagem

### 1. Algoritmo e ParamÃªtro
Utilizei o **Catboost Classifier** com a funÃ§Ã£o hiperparametros como **Learning Rate** (`0.01`) e **Class_Weight** (`balanced`).
* **Por que o Catboost venceu XGB, LGBM e RF?** Geralmente modelos boosting (XGB E LGBM) se sobressaem em analises preditivas, porÃ©m neste case, o Catboost se sobressaiu por conta de uma catecteristica que ele possui. Trato com variÃ¡veis categoricas. Por conta deste dataset ser majoritariamente formado por variÃ¡veis categÃ³ricas, ele acaba sendo o tipo de base perfeita para o Catboost performar, que foi o que ocorreu nessa rodada de treinos.
* **Por que Learning Rate e Class_Weight?** Por que no caso de anÃ¡lise de churns o mais dÃ­ficil Ã© aprender o padrÃ£o de comportamento numa base tÃ£o desbalanceada, e neste caso, a melhor soluÃ§Ã£o Ã© fazer que o modelo se atende a todo e qualquer detalhe no treinamento, fazendo com que o modelo nÃ£o passe por um comportamento ou indicio de possÃ­vel churn sem detecta-lÃ¡. Em conjunto com ele, o paramÃªtro class_weight ajuda muito dizendo para o modelo dar mais enfoque na classe minoritÃ¡ria (aumenta o peso da classe churn e ajuda o modelo a "ter medo" de perder possÃ­veis clientes churners).

### 2. Engenharia de Features
A estrutura de dados foi construÃ­da com `Scikit-Learn` incluindo:
* **Scaling:** do **"Total Charges"** e das features numÃ©ricas para menores escalas.
* **Imputer:** da mediana em features numÃ©ricas com missings e valores constantes em features categÃ³ricas.
* **Enconding:** em features catÃ©goricas.
* **Limpeza e TransformaÃ§Ã£o:** na feature **"Total Charges"** por conta de registro de espaÃ§o na coluna.


## ğŸ“Š Resultados (Test Validation PrÃ© Threshold)

| MÃ©tricas | Valor Final |
|----------|-------------|
| **Threshold** | **0.50** (Calibrador de probabilidades) |
| **Precision** | **54%** (Assertividade percentual dos apontamentos de fraude) |
| **Recall**    | **81%** (Capacidade de detecÃ§Ã£o) |
| **F1-Score**  | **65%** (EquilÃ­brio entre Precision x Recall) |
| **ROC AUC**   | **78%** (Capacidade de separaÃ§Ã£o entre Churn e NÃ£o churn) |


### Performance Test: Curva de CalibraÃ§Ã£o
> *O grÃ¡fico linha abaixo mostra como se comportou o modelo durante o teste, e sua performance de calibraÃ§Ã£o comparada ao modelo perfeito*

![Curva de CalibraÃ§Ã£o](img/calibration_curve_test.png)

### Performance Financeira Test
> *O grÃ¡fico de barras abaixo mostra o resultado financeiro do modelo.
Entregando um valor de **$9.000** dolares de prejuizo evitados, que equivalem a **70%** do total das tentativas de fraude*

![Resultado Financeiro Test](img/business_profit_curve_test.png)

## ğŸ“Š Resultados (Test Validation w/ Threshold)

| MÃ©tricas | Valor Final |
|----------|-------------|
| **Threshold** | **0.40** (Calibrador de probabilidades) |
| **Precision** | **70%** (Assertividade percentual dos apontamentos de fraude) |
| **Recall**    | **60%** (Capacidade de detecÃ§Ã£o) |
| **F1-Score**  | **65%** (EquilÃ­brio entre Precision x Recall) |
| **ROC AUC**   | **80%** (Capacidade de separaÃ§Ã£o entre Churn e NÃ£o churn) |


### Performance Calibrada: Curva de CalibraÃ§Ã£o
> *O grÃ¡fico linha abaixo mostra como se comportou o modelo durante a validaÃ§Ã£o com o threshold perfeito definido, e sua performance de calibraÃ§Ã£o comparada ao modelo de teste e o modelo perfeito*

![Curva de CalibraÃ§Ã£o Final](img/calibration_curve_val.png)

### Performance Financeira Calibrada
> *O grÃ¡fico de barras abaixo mostra o resultado financeiro do modelo calibrado.
Entregando um valor de **$14.000** dolares de prejuizo evitados, que equivalem a **X%** do total de churns ocorridos*

![Resultado Financeiro Calibrada](img/business_profit_curve_final.png)



## ğŸš€ Como Rodar o Projeto

1. **Clone o repositÃ³rio:**
   ```bash
   git clone [git@github.com:savioricardog/fraud-detection.git](https://github.com/savioricardog/fraud-detection.git)

2. **Instale as dependÃªncias:**
   ```bash 
   pip install -r requirements.txt

3. **Execute o arquivos :**
   ```bash 
   python fraud-detection-V2.py

## ğŸ“‚ Estrutura de Arquivos 

fraud-detection.py: Estrutura principal de treinamento.

fraud-detection.ipynb: Arquivo em modelo Jupyter.

requirements.txt: DependÃªncias do ambiente.

models/model_fraud_V2.pkl: Modelo treinado.


**Desenvolvido por Savio Ricardo Garcia ğŸ‘¨â€ğŸ’»**
