# ğŸšœ ClassificaÃ§Ã£o de Clientes que darÃ£o Churn (Catboost)

## ğŸ“‹ Sobre o Projeto
Este projeto resolve um problema muito comum em toda e qualquer empresa: Churn de clientes.

O principal desafio neste caso/projeto Ã© conseguir entender as ocilaÃ§Ãµes do comportamento humano, para assim conseguir traÃ§ar um padrÃ£o de perfil de usuÃ¡rios que da churn.

## ğŸ“‹ Entendimento de nÃ©gocios.
Realizando EDA pode-se concluir alguns padrÃµes que ajudam a basear a classifiÃ§Ã£o de Churn para tal Cliente.
Clientes mais propensos a churn utilizam menos produtos que clientes menos propensos.

## ğŸ§  EstratÃ©gia de Modelagem

### 1. Algoritmo e ParamÃªtro
Utilizei o **Catboost Classifier** com a funÃ§Ã£o hiperparametros como **Learning Rate** (`0.01`) e **Class_Weight** (`balanced`).
* **Por que o Catboost venceu XGB, LGBM e RF?** Geralmente modelos boosting (XGB E LGBM) se sobressaem em analises preditivas, porÃ©m neste case, o Catboost se sobressaiu por conta de uma catecteristica que ele possui. Trato com variÃ¡veis categoricas. Por conta deste dataset ser majoritariamente formado por variÃ¡veis categÃ³ricas, ele acaba sendo o tipo de base perfeita para o Catboost performar, que foi o que ocorreu nessa rodada de treinos.
* **Por que Learning Rate e Class_Weight?** Por que no caso de anÃ¡lise de churns o mais dÃ­ficil Ã© aprender o padrÃ£o de comportamento numa base tÃ£o desbalanceada, e neste caso, a melhor soluÃ§Ã£o Ã© fazer que o modelo se atende a todo e qualquer detalhe no treinamento, fazendo com que o modelo nÃ£o passe por um comportamento ou indicio de possÃ­vel churn sem detecta-lÃ¡. Em conjunto com ele, o paramÃªtro class_weight ajuda muito dizendo para o modelo dar mais enfoque na classe minoritÃ¡ria (aumenta o peso da classe churn e ajuda o modelo a "ter medo" de perder possÃ­veis clientes churners).

### 2. Engenharia de Features
A estrutura de dados foi construÃ­da com `Scikit-Learn` incluindo:
* **Escalonamento:** Escalonamento do montante e do tempo para menores escalas.


## ğŸ“Š Resultados (Test Validation)

| MÃ©tricas | Valor Final |
|----------|-------------|
| **Precision** | **92%** (Assertividade percentual dos apontamentos de fraude) |
| **Recall**    | **81%** (Capacidade de detecÃ§Ã£o) |
| **F1-Score**  | **86%** (EquilÃ­brio entre Precision x Recall) |

### Performance: Matrix de ConfusÃ£o
> *O grÃ¡fico de matrix de confusÃ£o abaixo mostra como se comportou o modelo durante o teste,
entregando um resultado mÃ¡ximo de **24** fraudes nÃ£o detectadas*

![Matrix de ConfusÃ£o](img/confusion_matrix_LIGHT.png)

### Performance Financeira
> *O grÃ¡fico de barras abaixo mostra o resultado financeiro do modelo.
Entregando um valor de **$9.000** dolares de prejuizo evitados, que equivalem a **70%** do total das tentativas de fraude*

![Resultado Financeiro](img/financial_model_impact.png)


## ğŸš€ Como Rodar o Projeto

1. **Clone o repositÃ³rio:**
   ```bash
   git clone [git@github.com:savioricardog/fraud-detection.git](https://github.com/savioricardog/fraud-detection.git)

2. **Instale as dependÃªncias:**
   ```bash 
   pip install -r requirements.txt

3. **Execute o arquivos :**
   ```bash 
   python fraud-detection-V2.py

## ğŸ“‚ Estrutura de Arquivos 

fraud-detection.py: Estrutura principal de treinamento.

fraud-detection.ipynb: Arquivo em modelo Jupyter.

requirements.txt: DependÃªncias do ambiente.

models/model_fraud_V2.pkl: Modelo treinado.


**Desenvolvido por Savio Ricardo Garcia ğŸ‘¨â€ğŸ’»**
