{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- IMPORTS ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from feature_engine import discretisation, encoding\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder, OrdinalEncoder, TargetEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, StackingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.frozen import FrozenEstimator\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.eng_funcs import CleanTransformStrNum, AnalyseDataSet, profit_calc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## -- CONFIGURING JUPYTER PAGE --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(experiment_id='1')\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## -- DOWNLOAD DATASET LATEST VERSION --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = kagglehub.dataset_download(\"yeanzc/telco-customer-churn-ibm-dataset\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## -- VARIABLES CONFIG --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = os.path.join(path, 'Telco_customer_churn.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- READ AND SAMPLE DATASET ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(path_dataset, engine = 'calamine')\n",
    "df.head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- FEATURE ENGINE ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## -- DF_AUX TEST --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_aux = df.copy()\n",
    "\n",
    "# ADJUSTING TOTAL CHARGES COLUMN\n",
    "df_aux['Total Charges'] = df_aux['Total Charges'].apply(lambda x: 0 if x == ' ' else x)\n",
    "\n",
    "# FEATURE RELATIVE PRICE UP OR DOWN\n",
    "df_aux['Price Up Recently'] = np.where(\n",
    "                            df_aux['Tenure Months'] > 0,\n",
    "                            df_aux['Total Charges'] / df_aux['Tenure Months'],\n",
    "                            df_aux['Monthly Charges'])\n",
    "\n",
    "# PERCENT PRICE DIFFERENCE\n",
    "df_aux['Price Hike'] = df_aux['Monthly Charges'] - df_aux['Price Up Recently']\n",
    "\n",
    "# FEATURE RELATIVE PRICE ESTIMATED VS PRICE PRICE PAYED\n",
    "df_aux['Price Sensitivity'] = df_aux['Monthly Charges'] / df_aux['CLTV']\n",
    "\n",
    "# SEPARATING SERVICE COLUMNS\n",
    "services_offer = ['Phone Service','Multiple Lines','Internet Service',\n",
    "                  'Online Security','Online Backup','Device Protection',\n",
    "                  'Tech Support','Streaming TV','Streaming Movies']\n",
    "\n",
    "# CREATING NEW FEATURES\n",
    "df_aux['Score dependency'] = 0\n",
    "df_aux['Lazer Products'] = 0\n",
    "df_aux['Security Product'] = 0\n",
    "\n",
    "# FLAG FEATURE ABOUT BOUGHT PRODUCTS\n",
    "for score in df_aux[services_offer]:\n",
    "    points = np.where(df_aux[score].astype(str).str.contains('No'), 0, 1)\n",
    "    df_aux['Score dependency'] = df_aux['Score dependency'] + points\n",
    "\n",
    "for lazer in df[['Streaming TV','Streaming Movies']]:\n",
    "    points = np.where(df[lazer].astype(str).str.contains('No'), 0, 1)\n",
    "    df_aux['Lazer Products'] = df_aux['Lazer Products'] + points\n",
    "\n",
    "for security in df[['Online Security','Online Backup','Device Protection']]:\n",
    "    points = np.where(df[security].astype(str).str.contains('No'), 0, 1)\n",
    "    df_aux['Security Product'] = df_aux['Security Product'] + points\n",
    "\n",
    "# SENIOR VULNERABILITY FLAG\n",
    "df_aux['Senior Vulnerable'] = np.where((df_aux['Senior Citizen'] == 'Yes') & (df_aux['Tech Support'] == 'No'), 1, 0)\n",
    "\n",
    "# FAMILY AMOUNT CONTRACT FLAG\n",
    "df_aux['Family'] = (df_aux['Partner'] == 'Yes').astype(int) + (df_aux['Dependents'] == 'Yes').astype(int)\n",
    "\n",
    "# CLUSTERING GEOSPACES\n",
    "X_geo = df_aux[['Latitude','Longitude']]\n",
    "kmeans = KMeans(n_clusters=30, random_state=42)\n",
    "df_aux['Geo Cluster'] = kmeans.fit_predict(X_geo).astype(str)\n",
    "\n",
    "# PAYMENT RISK FLAG\n",
    "df_aux['Payment Risk'] = np.where((df_aux['Payment Method'] == 'Credit card (automatic)') \n",
    "                                    | (df_aux['Payment Method'] == 'Bank transfer (automatic)'),\n",
    "                                        0, 1)\n",
    "\n",
    "# FEATURE REMAINING TIME CONTRACT \n",
    "df_aux['Time Contract'] = df_aux['Contract'].apply(lambda x: 24 if x == 'Two year' else\n",
    "                                                             12 if x == 'One year' else  1).astype(int)\n",
    "\n",
    "# MEASURING MONTHS FOR CONTRACT RENEWAL \n",
    "df_aux['Months to Renewal'] = df_aux['Time Contract'] - (df_aux['Tenure Months'] % df_aux['Time Contract'])\n",
    "\n",
    "\n",
    "# FINDING CONTRACT NEXT TO THE END\n",
    "df_aux['Last Three Months'] = np.where(df_aux['Time Contract'] <= 3, 1, 0)\n",
    "\n",
    "df_aux['High Tech No Support'] = np.where((df_aux['Internet Service'] == 'Fiber optic') & (df_aux['Tech Support'] == 'No'), 1, 0)\n",
    "\n",
    "# DISCOVERING MEAN PRICE BY SERVICE \n",
    "df_aux['Average Price P/ Service'] = df_aux['Monthly Charges'] / df_aux['Score dependency']\n",
    "\n",
    "# DISCOVERING MEAN PRICE BY GEOLOCATION\n",
    "df_aux['Average By Geo'] = df_aux.groupby(by=['Geo Cluster'])[['Monthly Charges']].transform('mean')\n",
    "\n",
    "# DISCOVERING PRICE DIFFERENCE BY CITY\n",
    "df_aux['Average By Geo'] = df_aux.groupby(by=['City'])[['Monthly Charges']].transform('mean')\n",
    "df_aux['Charge Diff City Mean'] = df_aux['Monthly Charges'] - df_aux['Average By Geo']\n",
    "\n",
    "# DISCOVERING TIME TO END CONTRACT RATIO\n",
    "df_aux['Tenure Ratio Contract'] = (df_aux['Time Contract'] - df_aux['Months to Renewal']) / df_aux['Time Contract']\n",
    "\n",
    "# DISCOVERING VALUE RATIO FOR CLTV BY MONTHLY CHARGES\n",
    "df_aux['Value Ratio'] = df_aux['CLTV'] / df_aux['Monthly Charges']\n",
    "\n",
    "# DISCOVERING HOW ISOLATED CHURN PERSON IS\n",
    "df_aux['Social Isolation'] = (df_aux['Family'].astype(int) + df_aux['Senior Vulnerable'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## -- JOINING DF_AUX WITH DF OFICIAL --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_columns = df_aux.columns.difference(df.columns)\n",
    "df = df.join(df_aux[new_columns])\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- UNDERSTANDING DATASET - EDA ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## -- DATASET GENERAL INFOS --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "print(f'\\n Shape df: {df.shape}')\n",
    "\n",
    "# DESCRIBING DATASET\n",
    "df.describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## -- ANALISING DATASET VALUES (IF HAS FALSE NULL VALUES OR TRUE NULL VALUES) --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION CREATED FOR ANALYSE DATASET\n",
    "AnalyseDataSet(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## -- CREATING RANGE COLUMNS FOR BETTER UNDERSTAND --\n",
    "\n",
    " CREATING TENURE MONTHS RANGE\n",
    "\n",
    " PLOTING CHURN DISTRIBUITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIST COLUMN TYPES\n",
    "blacklist = ['CustomerID','City','Lat Long','Churn Label', 'Monthly Charges','Zip Code',\n",
    "             'Latitude','Longitude','CLTV','Churn Score',\n",
    "             'Total Charges', 'Tenure Months']\n",
    "category_cols = df.select_dtypes(include=['object'])\n",
    "num_cols = df.select_dtypes(include=['int','float'])\n",
    "\n",
    "cat_cols = [col for col in category_cols.columns if col in category_cols and col not in blacklist]\n",
    "num_cols = [col for col in df.columns if col in num_cols and col not in blacklist]\n",
    "\n",
    "# CATEGORICAL COUNTPLOT\n",
    "plt.figure(figsize=(40, 36), dpi=350)\n",
    "for i, col in enumerate(cat_cols):\n",
    "    plt.subplot(6, 5, i+1)\n",
    "    sns.countplot(data=df, x=col, hue='Churn Value', palette='magma')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f'Churn for {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# NUMERICAL COUNTPLOT\n",
    "plt.figure(figsize=(40, 36), dpi=350)\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot(6, 5, i+1)\n",
    "    sns.countplot(data=df, x=col, hue='Churn Value', palette='coolwarm')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(f'Churn for {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- X,y AND Train/Test ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target = 'Churn Value'\n",
    "X, y = df.drop(columns=[target], errors='ignore'), df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.25)\n",
    "\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- SEPARATING EACH ESPECIFIC TYPE VALUE (STR, NUM, DATE, CODE) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# UNUSED VALUES (LEAKAGE|OVERFITTING)\n",
    "blacklist = ['Churn Score','Churn Label', 'CustomerID', 'Count', \n",
    "             'Total Charges', 'Tenure Months Range','Churn Score Range',\n",
    "             'Lat Long', 'Churn Reason']\n",
    "\n",
    "num_vars = [col for col in X_train.columns \n",
    "            if col not in blacklist and pd.api.types.is_numeric_dtype(X_train[col])]\n",
    "cat_vars = [col for col in X_train.columns \n",
    "            if col not in blacklist and pd.api.types.is_object_dtype(X_train[col])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- NUMBER/OBJECT PIPELINE TRANSFORMATION ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "totalcharge_pipe = Pipeline([\n",
    "    ('eng', CleanTransformStrNum()),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- PREPROCESSOR DATA ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tr_num', num_pipe, num_vars),\n",
    "        ('tr_cat', cat_pipe, cat_vars),\n",
    "        ('totalcharges', totalcharge_pipe, ['Total Charges']),\n",
    "        ], \n",
    "    remainder='drop'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- DEFINING PARAMETERS ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = [\n",
    "    # --- MODEL 1: RandomForestClassifier: The Slowest ---\n",
    "    {\n",
    "    'model': [RandomForestClassifier(n_jobs=1, random_state=42, verbose=1 )],\n",
    "    'model__n_estimators': [250, 500, 750],\n",
    "    'model__max_depth': [3,6, 10, None],\n",
    "    'model__class_weight': ['balanced', 'balanced_subsample', None],\n",
    "    'model__min_samples_leaf': [1, 3]\n",
    "    },\n",
    "    # --- MODEL 2: LGBMClassifier: The Fastest ---\n",
    "    {\n",
    "    'model': [LGBMClassifier(n_jobs=1, force_col_wise=True, random_state=42)],\n",
    "    'model__n_estimators': [600, 1000, 2000],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'model__num_leaves': [45, 75, 100],\n",
    "    'model__max_depth': [-1],\n",
    "    'model__class_weight': ['balanced', None],\n",
    "    'model__min_child_samples': [4, 12, 20],\n",
    "    'model__subsample': [0.8],\n",
    "    'model__colsample_bytree': [ 0.8],\n",
    "    'model__importance_type': ['gain'],\n",
    "    'model__objective': ['binary']\n",
    "    },\n",
    "    # --- MODEL 3: XGBOOST: The Most Robust ---\n",
    "    {\n",
    "    'model': [XGBClassifier(n_jobs=1, force_col_wise=True, random_state=42)],\n",
    "    'model__n_estimators': [200, 500, 900],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'model__max_depth': [3, 6, 8],\n",
    "    'model__scale_pos_weight': [1, 3, 5, None],\n",
    "    'model__min_child_samples': [1, 3, 8],\n",
    "    'model__subsample': [0.8],\n",
    "    'model__colsample_bytree': [0.8],\n",
    "    'model__gamma': [0.1], # PENALITY MODEL FOR AVOID UNUSABLE LEAVES\n",
    "    'model__eval_metric': ['logloss'],\n",
    "    'model__gamma':[0, 0.1, 1]\n",
    "    },\n",
    "    # --- MODEL 4: CATBOOST: Works Better W/ Categorical Datasets ---\n",
    "    {\n",
    "    'model': [CatBoostClassifier(allow_writing_files=False, verbose=1, random_state=42)],\n",
    "    'model__n_estimators': [500, 1000, 1500],\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'model__depth': [4, 6, 9],\n",
    "    'model__auto_class_weights': ['Balanced'],\n",
    "    'model__l2_leaf_reg': [3, 5, 7],\n",
    "    'model__border_count': [128]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- DEFINING PARAMETERS ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_pipe = Pipeline([\n",
    "    ('model', KNeighborsClassifier())\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- APPLYING GRIDSEARCH ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CONFIGURATION GRIDSERACH PARAMS\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "grid = RandomizedSearchCV(\n",
    "    estimator=model_pipe,\n",
    "    param_distributions = params,\n",
    "    n_iter=100,\n",
    "    cv = kfold,\n",
    "    scoring='roc_auc',\n",
    "    verbose=1,\n",
    "    n_jobs=10,\n",
    "    random_state=42,\n",
    "    refit = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- FINAL PIPE ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "final_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('grid', grid)\n",
    "    ],\n",
    "    memory=None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- FITTING MODEL PIPELINE ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with mlflow.start_run() as r:\n",
    "\n",
    "    # RUNNING MLFLOW LOG\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    #/*****************************************************************************************/\n",
    "\n",
    "    # FITTING MODEL\n",
    "    print(\"Fitting model!\")\n",
    "    model_fit = final_pipe.fit(X_train, y_train)\n",
    "    print(\"Model fitted!\")\n",
    "    \n",
    "    #/*****************************************************************************************/\n",
    "\n",
    "    # PREDICTING AND METRICS\n",
    "    print(\"Doing Train Predict!\")\n",
    "    y_pred_train = model_fit.predict(X_train)\n",
    "    y_proba_train = model_fit.predict_proba(X_train)[:, 1]\n",
    "    roc_train_score = metrics.roc_auc_score(y_train, y_pred_train)\n",
    "    f1_score_train = metrics.f1_score(y_train, y_pred_train)\n",
    "    prauc_score_train = metrics.average_precision_score(y_train, y_pred_train)\n",
    "    print(\"Train Predict Conclued!\")\n",
    "\n",
    "    print(\"Doing Test Predict!\")\n",
    "    y_pred_test = model_fit.predict(X_test)\n",
    "    y_proba_test = model_fit.predict_proba(X_test)[:, 1]\n",
    "    roc_test_score = metrics.roc_auc_score(y_test, y_pred_test)\n",
    "    f1_score_test = metrics.f1_score(y_test, y_pred_test)\n",
    "    prauc_score_test = metrics.average_precision_score(y_test, y_pred_test)\n",
    "    print(\"Test Predict Conclued!\")\n",
    "\n",
    "    \n",
    "    # PLOTING ROC CURVE AND F1 SCORE\n",
    "    roc_train = metrics.roc_curve(y_train, y_proba_train)\n",
    "    roc_test = metrics.roc_curve(y_test, y_proba_test)\n",
    "\n",
    "    plt.figure(dpi=350)\n",
    "    plt.plot(roc_train[0], roc_train[1])\n",
    "    plt.plot(roc_test[0], roc_test[1])\n",
    "    plt.legend([f\"Train: {roc_train_score:.2f}\",\n",
    "               f\"Test: {roc_test_score:.2f}\"])\n",
    "    plt.plot([0,1],[0,1], '--', color='black')\n",
    "    plt.grid(True)\n",
    "    plt.title(f'Roc Curve (Train/Test)')\n",
    "    plt.savefig('img/roc_curve_train_test.png')\n",
    "    mlflow.log_artifact('img/roc_curve_train_test.png')\n",
    "    plt.show()\n",
    "\n",
    "    best_model = model_fit.named_steps['grid'].best_estimator_.named_steps['model']\n",
    "    model_name = best_model.__class__.__name__\n",
    "\n",
    "    # PRINT METRICS\n",
    "    print('='*40)\n",
    "    print(f'AUC SCORE: {roc_test_score:.2f}')\n",
    "    print('='*40)\n",
    "    print(f'F1 SCORE: {f1_score_test:.2f}')\n",
    "    print('='*40)\n",
    "    print(f'BEST ESTIMATOR: {model_name}')\n",
    "    print('='*40)\n",
    "\n",
    "    # TRIYNG IMPROVE MODL WITH THRESHOLD VALUE\n",
    "    threshhold_first_test = 0.5\n",
    "    if len(y_proba_test.shape) > 1 and y_proba_test.shape[1] > 1:\n",
    "        y_pred_threshold = (y_proba_test[:, 1] >= threshhold_first_test).astype(int)\n",
    "    else:\n",
    "        y_pred_threshold = (y_proba_test >= threshhold_first_test).astype(int)\n",
    "    f1_score_threshold = metrics.f1_score(y_test, y_pred_threshold)\n",
    "    \n",
    "    print('='*40)\n",
    "    print(f\"F1 Score threshold: {f1_score_threshold:.2f}\")\n",
    "    print('='*40)\n",
    "\n",
    "    # PRINTING CLASSIFICATION REPORT TEST\n",
    "    print(\"--- Classification Report - TEST ---\")\n",
    "    print(metrics.classification_report(y_test, y_pred_test))\n",
    "\n",
    "    # PRINTING CONFUSION MATRIX\n",
    "    print(\"--- Confusion Matrix ---\")\n",
    "    metrics.ConfusionMatrixDisplay.from_predictions(y_test, y_pred_test, cmap='Blues')\n",
    "    plt.show()\n",
    "\n",
    "    # CALCULATING PROFITS WITH CHURNERS SAVED BY MODEL PR√â THRESHOLD\n",
    "    ltv_test = X_test['CLTV'].mean()\n",
    "    cost_test = ltv_test * 0.05\n",
    "    sr_test = 0.5 # success rate\n",
    "    threshold_profit_test = np.linspace(0, 1, 101)\n",
    "    profits_test = [profit_calc(y_test, y_proba_test, ltv=ltv_test, cost=cost_test, sr=sr_test, threshold=t) for t in threshold_profit_test]\n",
    "\n",
    "    best_idx_profit = np.argmax(profits_test)\n",
    "    best_threshold_profit_test = threshold_profit_test[best_idx_profit]\n",
    "    max_proft_test = profits_test[best_idx_profit]\n",
    "\n",
    "    # PROFIT CURVE\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(threshold_profit_test, profits_test, label='Estimated Profit', color='green', linewidth = 2.0)\n",
    "\n",
    "    # FIND BETTER FINANCIAL POINT\n",
    "    plt.scatter(best_threshold_profit_test, max_proft_test, color='red', s=100, zorder=5)\n",
    "    plt.axvline(best_threshold_profit_test, linestyle='--', color='red', alpha=0.5, label=f'Best ThresHold for Profits {best_threshold_profit_test:.2f}')\n",
    "\n",
    "    # THRESHOLD PROFITS VS THRESHOLD MODEL\n",
    "    plt.axvline(threshhold_first_test, linestyle=':', color='blue', label=f'ThresHold F1 {threshhold_first_test:.2f}' )\n",
    "\n",
    "    plt.title(f'Profit Test Curve by ThresHold \\n Profit Max {max_proft_test:,.2f} in {best_threshold_profit_test:.2f}', fontsize=14)\n",
    "    plt.xlabel('Decision ThresHold (probability)', fontsize=12)\n",
    "    plt.ylabel('Estimated Profit', fontsize = 12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('img/business_profit_curve_test.png')\n",
    "    mlflow.log_artifact('img/business_profit_curve_test.png')\n",
    "    plt.show()\n",
    "\n",
    "    good_preds_test = (y_proba_test >= best_threshold_profit_test).astype(int)\n",
    "    tn_test, fp_test, fn_test, tp_test = metrics.confusion_matrix(y_test, good_preds_test).ravel()\n",
    "\n",
    "    total_money_risk_test = (tp_test + fn_test) * ltv_test\n",
    "    percent_save_test = (max_proft_test / total_money_risk_test) * 100\n",
    "\n",
    "    print('='*40)\n",
    "    print(f'Financial Impact Analysis (In Test)')\n",
    "    print(f'Total Risk Money {total_money_risk_test:.2f}')\n",
    "    print(f'Model Estimated Profit {max_proft_test:.2f}')\n",
    "    print(f'Percent Loss Saved {percent_save_test:.2f}')\n",
    "    print('='*40)\n",
    "\n",
    "    mlflow.log_metric(\"pct_revenue_saved_test\", percent_save_test)\n",
    "    mlflow.log_metric(\"total_money_at_risk_test\", total_money_risk_test)\n",
    "    #/*****************************************************************************************/\n",
    "\n",
    "    # TOP 10 BEST ESTIMATORS\n",
    "    cols_keeped = ['params','mean_test_score','std_test_score','rank_test_score']\n",
    "    results_df = pd.DataFrame(model_fit.named_steps[\"grid\"].cv_results_)\n",
    "    results_df = results_df[cols_keeped]\n",
    "    results_df = results_df.sort_values(by='rank_test_score')\n",
    "    print('Top 10 Grid Models')\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    display(results_df.head(5))\n",
    "\n",
    "    #/*****************************************************************************************/\n",
    "\n",
    "    # DF FEATURE IMPORTANCE\n",
    "    importance = best_model.feature_importances_/100\n",
    "    preprocessor_steps = model_fit.named_steps['preprocessor']\n",
    "    features_names = preprocessor_steps.get_feature_names_out()\n",
    "\n",
    "    df_importance = pd.DataFrame({\n",
    "        'Feature': features_names,\n",
    "        'Importance': importance\n",
    "    }).sort_values(by='Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(data=df_importance.head(10), x='Importance', y='Feature', \n",
    "                palette='viridis', hue = 'Feature', legend=False)\n",
    "    plt.title(F'Feature Importance ({best_model})')\n",
    "    plt.show()\n",
    "    print(df_importance.head(10))\n",
    "\n",
    "    #/*****************************************************************************************/\n",
    "\n",
    "    # TESTING CALIBRATION CURVE FOR UNDERSTAND BETTER THRESHOLD\n",
    "    prob_true, prob_pred = calibration_curve(y_test, y_proba_test, n_bins=10, strategy='uniform')\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.plot(prob_pred, prob_true, marker='o', linewidth=2, label=model_name)\n",
    "    plt.plot([0,1], [0,1], linestyle='--', color='gray', label='Calibrated Perfectly')\n",
    "    plt.ylabel('Real Positive Frac (Reality)')\n",
    "    plt.xlabel('Predicted Probability (Model predict)')\n",
    "    plt.title('Calibration Curve (Test)')\n",
    "    plt.legend()\n",
    "    plt.savefig('img/calibration_curve_test.png')\n",
    "    mlflow.log_artifact('img/calibration_curve_test.png')\n",
    "    plt.show()\n",
    "\n",
    "    X_calib, X_val, y_calib, y_val = train_test_split(X_test, y_test,\n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=y_test\n",
    "    )\n",
    "    model_calibrate = final_pipe\n",
    "    final_model = CalibratedClassifierCV(FrozenEstimator(model_calibrate), method='sigmoid')\n",
    "    final_model.fit(X_calib, y_calib)\n",
    "    y_val_calibrated = final_model.predict(X_val)\n",
    "    prob_val_calibrated = final_model.predict_proba(X_val)[:, 1]\n",
    "    y_true_val, y_prob_val = calibration_curve(y_val, prob_val_calibrated, n_bins=10)\n",
    "    y_true_test, y_prob_test = calibration_curve(y_test, y_proba_test, n_bins=10)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(y_prob_val, y_true_val, marker='s', label='Calibrated (Sigmoid)', color='green')\n",
    "    plt.plot(y_prob_test, y_true_test, marker='o', label='Original (Catboost)', color='red')\n",
    "    plt.plot([0,1], [0,1], linestyle='--', color='gray', label='Calibrated Perfectly')\n",
    "    plt.title('Calibration (Val): Before (Exaggerated) vs After (Realistic)')\n",
    "    plt.xlabel('Predicted Probability (Model predict)')\n",
    "    plt.ylabel('Real Positive Frac (Reality)')\n",
    "    plt.legend()\n",
    "    plt.savefig('img/calibration_curve_val.png')\n",
    "    mlflow.log_artifact('img/calibration_curve_val.png')\n",
    "    plt.show()\n",
    "\n",
    "        # PRINTING CLASSIFICATION REPORT\n",
    "    print(\"--- Classification Report - VALIDATION ---\")\n",
    "    print(metrics.classification_report(y_val, y_val_calibrated))\n",
    "\n",
    "    #/*****************************************************************************************/\n",
    "\n",
    "    # FINDING BEST THRESHOLD FOR MODEL\n",
    "    threshold_val = np.arange(0.1, 0.9, 0.1)\n",
    "    f1_scores = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    auc_scores = []\n",
    "\n",
    "    for t in threshold_val:\n",
    "        preds = (prob_val_calibrated >= t).astype(int)\n",
    "\n",
    "        f1_scores.append(metrics.f1_score(y_val, preds))\n",
    "        precisions.append(metrics.precision_score(y_val, preds, zero_division=0))\n",
    "        recalls.append(metrics.recall_score(y_val, preds))\n",
    "        auc_scores.append(metrics.roc_auc_score(y_val, preds))\n",
    "\n",
    "    best_thresh = np.argmax(f1_scores)\n",
    "    best_t = threshold_val[best_thresh]\n",
    "    best_f1 = f1_scores[best_thresh]\n",
    "    best_precision = precisions[best_thresh]\n",
    "    best_recall = recalls[best_thresh]\n",
    "    best_roc_auc = auc_scores[best_thresh]\n",
    "\n",
    "\n",
    "    # PRINTING METRICS WITH THRESHOLD\n",
    "    print(f'üí∞ Result Final Prod')\n",
    "    print('='*40)\n",
    "    print(f'üéØ Great Threshold: {best_t:.2f}')\n",
    "    print(f'üèÜ Best F1-Score: {best_f1:.4f}')\n",
    "    print(f'‚úÖ Best Precision-Score: {best_precision:.4f} (Of each 100 calls, we take {int(best_precision*100)} customers)')\n",
    "    print(f'üé£ Best Recall-Score: {best_recall:.4f} (Recovered {int(best_recall*100)}% of Churners)')\n",
    "    print(f'üéñÔ∏è Best ROC AUC-Score: {best_roc_auc:.4f}')\n",
    "\n",
    "    #/*****************************************************************************************/\n",
    "\n",
    "    # CALCULATING PROFITS WITH CHURNERS SAVED BY MODEL\n",
    "    ltv = X_val['CLTV'].mean()\n",
    "    cost = ltv * 0.05\n",
    "    sr = 0.5 # success rate\n",
    "    threshold_profit = np.linspace(0, 1, 101)\n",
    "    profits = [profit_calc(y_val, prob_val_calibrated, ltv=ltv, cost=cost, sr=sr, threshold=t) for t in threshold_profit]\n",
    "\n",
    "    best_idx_profit = np.argmax(profits)\n",
    "    best_threshold_profit = threshold_profit[best_idx_profit]\n",
    "    max_profit = profits[best_idx_profit]\n",
    "\n",
    "    # PROFIT CURVE\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(threshold_profit, profits, label='Estimated Profit', color='green', linewidth = 2.0)\n",
    "\n",
    "    # FIND BETTER FINANCIAL POINT\n",
    "    plt.scatter(best_threshold_profit, max_profit, color='red', s=100, zorder=5)\n",
    "    plt.axvline(best_threshold_profit, linestyle='--', color='red', alpha=0.5, label=f'Best ThresHold for Profits {best_threshold_profit:.2f}')\n",
    "\n",
    "    # THRESHOLD PROFITS VS THRESHOLD MODEL\n",
    "    plt.axvline(best_t, linestyle=':', color='blue', label=f'ThresHold F1 {best_t:.2f}' )\n",
    "\n",
    "    plt.title(f'Profit Val Curve by ThresHold \\n Profit Max {max_profit:,.2f} in {best_threshold_profit:.2f}', fontsize=14)\n",
    "    plt.xlabel('Decision ThresHold (probability)', fontsize=12)\n",
    "    plt.ylabel('Estimated Profit', fontsize = 12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('img/business_profit_curve_final.png')\n",
    "    mlflow.log_artifact('img/business_profit_curve_final.png')\n",
    "    plt.show()\n",
    "\n",
    "    good_preds_val = (prob_val_calibrated >= best_threshold_profit).astype(int)\n",
    "    tn_val, fp_val, fn_val, tp_val = metrics.confusion_matrix(y_val, good_preds_val).ravel()\n",
    "\n",
    "    total_money_risk_val = (tp_val + fn_val) * ltv\n",
    "    percent_save_val = (max_profit / total_money_risk_val) * 100\n",
    "\n",
    "    print('='*40)\n",
    "    print(f'Financial Impact Analysis (In val)')\n",
    "    print(f'Total Risk Money {total_money_risk_val:.2f}')\n",
    "    print(f'Model Estimated Profit {max_profit:.2f}')\n",
    "    print(f'Percent Loss Saved {percent_save_val:.2f}')\n",
    "    print('='*40)\n",
    "\n",
    "    mlflow.log_metric(\"pct_revenue_saved_val\", percent_save_val)\n",
    "    mlflow.log_metric(\"total_money_at_risk_val\", total_money_risk_val)\n",
    "\n",
    "    #/*****************************************************************************************/\n",
    "\n",
    "    # DEFINING SIGNATURE MODEL\n",
    "    input_sample = X_val.iloc[:5].copy().reset_index(drop=True)\n",
    "    prediction_sample = final_model.predict(input_sample)\n",
    "\n",
    "    signature = infer_signature(input_sample, prediction_sample)\n",
    "\n",
    "    # SAVING FINAL MODEL INFOS\n",
    "    mlflow.set_tag(\"winner_algorithm\", model_name)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=final_model,\n",
    "        name='churn_model_calibrated_prod',\n",
    "        signature=signature,\n",
    "        input_example=input_sample,\n",
    "        pip_requirements=['catboost','scikit-learn','pandas','numpy']\n",
    "    )\n",
    "\n",
    "    # SAVING FINAL MODEL METRICS\n",
    "    mlflow.log_metrics({\n",
    "        \"auc_train\": roc_train_score,\n",
    "        \"auc_test\": roc_test_score,\n",
    "        \"f1_train\": f1_score_train,\n",
    "        \"f1_test\": f1_score_test,\n",
    "        \"f1 threshold\": f1_score_threshold,\n",
    "        \"prauc_train\": prauc_score_train,\n",
    "        \"prauc_test\": prauc_score_test,\n",
    "        \"f1_val\": best_f1,\n",
    "        \"precision_val\": best_precision,\n",
    "        \"recall_val\": best_recall,\n",
    "        \"auc_val\": best_roc_auc\n",
    "    })  # type: ignore\n",
    "\n",
    "    print(\"‚úÖ Completed!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # --- LOADING MODEL ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "versions = mlflow.search_model_versions(filter_string= \"name = 'model_churn'\")\n",
    "last_version = max([int(i.version) for i in versions])\n",
    "model = mlflow.sklearn.load_model(f'models:///model_churn/{last_version}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## --- READING NEW DATA ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    \"Country\": 'United States',\n",
    "    \"State\": 'California',\n",
    "    \"City\": 'Los Angeles',\n",
    "    \"Zip Code\":\t90003,\n",
    "    \"Latitude\": 33.964131,\n",
    "    \"Longitude\": -118.272783,\n",
    "    \"Gender\":'Male',\n",
    "    \"Senior Citizen\": 'No',\n",
    "    \"Partner\": 'No',\n",
    "    \"Dependents\": 'No',\n",
    "    \"Tenure Months\": 5,\n",
    "    \"Phone Service\": 'Yes'\t,\n",
    "    \"Multiple Lines\": 'No',\n",
    "    \"Internet Service\": 'DSL',\n",
    "    \"Online Security\": 'No',\n",
    "    \"Online Backup\": 'Yes',\n",
    "    \"Device Protection\": 'Yes'\t,\n",
    "    \"Tech Support\":\t'Yes',\n",
    "    \"Streaming TV\":\t'No',\n",
    "    \"Streaming Movies\":\t'No',\n",
    "    \"Contract\": 'Month-to-month',\n",
    "    \"Paperless Billing\": 'No',\n",
    "    \"Payment Method\": 'Bank transfer (automatic)',\n",
    "    \"Monthly Charges\": 75.9,\n",
    "    \"Total Charges\": 203.79,\n",
    "    \"CLTV\": 10000,\n",
    "    \"Average By Geo\": 62.42377,\n",
    "    \"Average Price P/ Service\": 36.98,\n",
    "    \"Charge Diff City Mean\": -28.377,\n",
    "    \"Family\": 1,\n",
    "    \"Geo Cluster\": 30,\n",
    "    \"High Tech No Support\": 0,\n",
    "    \"Last Three Months\": 0,\n",
    "    \"Lazer Products\": 1,\n",
    "    \"Months to Renewal\": 2,\n",
    "    \"Payment Risk\": 1,\n",
    "    \"Price Hike\": -9.733,\n",
    "    \"Price Sensitivity\": 0.003,\n",
    "    \"Price Up Recently\": 91.3102,\n",
    "    \"Score dependency\": 4,\n",
    "    \"Security Product\": 2,\n",
    "    \"Senior Vulnerable\": 0,\n",
    "    \"Social Isolation\": 0,\n",
    "    \"Tenure Ratio Contract\": 0.0,\n",
    "    \"Time Contract\": 2,\n",
    "    \"Value Ratio\": 120.304078,\n",
    "}, index=[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## --- PREDICTING WITH NEW VALUES ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "proba = model.predict_proba(new_data)[:, 1]\n",
    "threshold_great = 0.40\n",
    "final_decision = (proba >= threshold_great).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## --- ANALYSING NEW RESULT ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(f\"üé≤ Probabilidade de Churn: {proba[0]*100:.2f}%\")\n",
    "print(f\"‚öñÔ∏è Decision (ThresHold {threshold_great}): {'üî¥ CHURN' if final_decision[0] == 1 else 'üü¢ RETAIN'}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
